## Bandwidth available to nodes
bandwidths:
  - src_id: 1
    dest_id: 2
    bandwidth: 1000000

default_bandwidth: 1000000

## Data streaming info
default_window_interval: 60
default_window_limit: 20
default_kafka_server: "10.2.32.91:9092"
default_test_directory: "/TreeNN/data/"

## Docker specific fields
default_cpus: 0.8
default_memory: "256M"
default_docker_image: "mayanksinghal/distributedlearning:simulator"
default_host_test_directory: "~/Simulator/mnist_data/test"
default_policy: 0
default_args: 0

## Machine info
machine:
-   ip: 10.129.26.111
    username: "ub"
    password: "spark!sfun"

## Kafka script automation 
kafka:
   script_name: "5-worker.sh"
   directory: "sensor/mnist"
   interarrival_time: 0.25
   address: "10.2.32.91:9092"

## arguments to be passed to the learning model
application_arguments:
-   model             : 'MNIST'
    input_size        : 784
    output_size       : 10
    num_hidden_layers : 3
    hidden_layer_sizes: [20,10,10]
    alpha             : 0.4
    batch_size        : 20
    epochs            : 10

## Learning Type
learning: 'Asynchronous' # Available choices are 'Synchronous' and 'Asynchronous'

## Policy for sharing models
policy:
-   type: 'SimplePolicy'
    args: 
-   type: 'TimePolicy'
    args:
    -   push_interval: 50
        pull_interval: 50
    -   push_interval: 50
        pull_interval: 50
-   type: 'WindowPolicy'
    args:
        push_count: 1
        pull_count: 400
-   type: 'AccuracyPolicy'
    args:
        threshold: 2

nodes:
-   id: 1 
    port: 8040
    machine: 0
    cpus: 2
-   id: 2
    port: 8041
    machine: 0
    parent_id: 1
    sensors: [0]
-   id: 3
    port: 8042
    machine: 0
    parent_id: 1
    sensors: [1]
-   id: 4
    port: 8043
    machine: 0
    parent_id: 1
    sensors: [2]
-   id: 5
    port: 8044
    machine: 0
    parent_id: 1
    sensors: [3]
-   id: 6
    port: 8045
    machine: 0
    parent_id: 1
    sensors: [4]

cloud:
    machine: 0
    port: 9040
    cpus: 10
    memory: "512M"